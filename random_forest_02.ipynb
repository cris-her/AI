{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    },
    "latex_envs": {
      "LaTeX_envs_menu_present": true,
      "autocomplete": true,
      "bibliofile": "biblio.bib",
      "cite_by": "apalike",
      "current_citInitial": 1,
      "eqLabelWithNumbers": true,
      "eqNumInitial": 1,
      "hotkeys": {
        "equation": "Ctrl-E",
        "itemize": "Ctrl-I"
      },
      "labels_anchors": false,
      "latex_user_defs": false,
      "report_style_numbering": false,
      "user_envs_cfg": false
    },
    "colab": {
      "name": "random_forest_02.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cris-her/AI/blob/master/random_forest_02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qktljd2h0z2A"
      },
      "source": [
        "import warnings\n",
        "warnings.simplefilter(\"ignore\")"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q0yW-5-P0z2B"
      },
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1i-7gS40z2D"
      },
      "source": [
        "## Ensembles"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20STNHw_0z2D"
      },
      "source": [
        "**Concepto General**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_AWrP4d90z2D"
      },
      "source": [
        "Random Forest y Gradient Boosted Trees, forman parte de una familia de algoritmos que se denominan ensembles.\n",
        "\n",
        "$$ Ensemble = Submodelos \\rightarrow Entrenamiento \\rightarrow Predicciones_{Intermedias} \\rightarrow Voto \\rightarrow Prediccion_{final}$$ "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_CU4m-B0z2D"
      },
      "source": [
        "** Cómo funciona el algoritmo Random Forest?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-CJSwLEE0z2D"
      },
      "source": [
        "Vamos a generar cientos de modelos de arboles de decisión que serán entrenados sobre **conjuntos de datos bootstrapeados** del conjunto de datos original y donde para cada etapa de separación el **conjunto de features elegibles** sera un subconjunto aleatorio del conjunto original de features."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTxtw52G0z2D"
      },
      "source": [
        "<img src=\"https://raw.githubusercontent.com/cris-her/machine-learning-platzi/master/img/rf_tree.png\" width=\"600\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7vZ9AQUD0z2E"
      },
      "source": [
        "Cada uno de los arboles entrenados luego podrá votar por su predicción y promediaremos estos votos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gUBzo8QH0z2E"
      },
      "source": [
        "<img src=\"https://raw.githubusercontent.com/cris-her/machine-learning-platzi/master/img/random_forest.png\" width=\"600\">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-PIsj9an9wlK"
      },
      "source": [
        "X = pd.read_csv('https://raw.githubusercontent.com/cris-her/datasets-platzi-course/master/intermediate_results/X_opening.csv')\n",
        "y = X['worldwide_gross']\n",
        "X = X.drop('worldwide_gross',axis=1)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FMwBjMYG0z2E"
      },
      "source": [
        "**Ensembles del pobre (\"Poor man's ensembles\")**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qh7EzlD30z2E"
      },
      "source": [
        "- Entrenar diversos modelos a mano\n",
        "- Promediar el resultado\n",
        "- Owen Zhang, número 1 de Kaggle.com durante un largo tiempo, ocupaba esta estrategia promediando diversos modelos XGBoost.\n",
        "- ``from sklearn.ensemble import VotingClassifier`` sirve por ejemplo para hacer un ensemble manual de clasificación\n",
        "\n",
        "En general los ensembles del pobre funcionan ya que cada uno de los modelos que votarán en conjunto son bastante fuertes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iy2K-1IT0z2E"
      },
      "source": [
        "**Porqué RF es poderoso?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eH92CvuH0z2E"
      },
      "source": [
        "<div class=\"alert alert-success\">\n",
        "  **Leo Breiman** creador del Random Forest demostró que un ensemble podía tener buen poder de generalización sí:\n",
        "  <ol>\n",
        "    <li>Los submodelos tienen buen poder de predicción</li>\n",
        "    <li>Los submodelos están descorrelacionados</li>\n",
        "    </ol>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNr-CLoS0z2E"
      },
      "source": [
        "Así el algoritmo de Random Forest compromete un poco de poder de predicción de cada uno de los decision trees que arma, pero la forma aleatoria de generarlos hace que esten **fuertemente descorrelacionados**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HgC_gASk0z2E"
      },
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import cross_validate\n",
        "\n",
        "forest = RandomForestRegressor(200)\n",
        "results = cross_validate(forest,X,y,cv=5,scoring='r2')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBYS2cWl0z2E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ef74362-4ab5-490d-96b2-37f1a2631222"
      },
      "source": [
        "test_scores = results['test_score']\n",
        "#train_scores = results['train_score']\n",
        "#print(np.mean(train_scores))\n",
        "print(np.mean(test_scores))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.5135429075491713\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGRJczNb0z2E"
      },
      "source": [
        "Mejor resultado que Lasso! Ya no tenemos Bias y tenemos un mejor score r2. Sin embargo tenemos una diferencia importante entre score de entrenamiento y de test (overfit)."
      ]
    }
  ]
}